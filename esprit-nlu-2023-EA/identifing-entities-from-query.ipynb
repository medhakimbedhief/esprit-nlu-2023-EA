{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"hf_tag = \"ethzanalytics/gpt-j-6B-8bit-sharded\" #@param {type:\"string\"}","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:55:47.296920Z","iopub.execute_input":"2023-05-19T22:55:47.297289Z","iopub.status.idle":"2023-05-19T22:55:47.303911Z","shell.execute_reply.started":"2023-05-19T22:55:47.297259Z","shell.execute_reply":"2023-05-19T22:55:47.302970Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#@markdown setup logging\nimport logging\nfrom pathlib import Path\nfor handler in logging.root.handlers[:]:\n    logging.root.removeHandler(handler)\n    \ndas_logfile = Path.cwd() / \"generate.log\"\n\nlogging.basicConfig(\n    level=logging.INFO,\n    filename=das_logfile,\n    filemode='w',\n    format=\"%(asctime)s %(levelname)s %(message)s\",\n    datefmt=\"%m/%d/%Y %I:%M:%S\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:55:48.502804Z","iopub.execute_input":"2023-05-19T22:55:48.503520Z","iopub.status.idle":"2023-05-19T22:55:48.512349Z","shell.execute_reply.started":"2023-05-19T22:55:48.503483Z","shell.execute_reply":"2023-05-19T22:55:48.511126Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#@markdown check  system stats\nfrom psutil import virtual_memory\nimport os\nram_gb = round(virtual_memory().total / (1024**3), 1)\nprint(f'Runtime has {ram_gb} gigs of memory and {os.cpu_count()} processors')\nlogging.info(f'Runtime has {ram_gb} gigs of memory and {os.cpu_count()} processors')","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:55:50.068232Z","iopub.execute_input":"2023-05-19T22:55:50.068652Z","iopub.status.idle":"2023-05-19T22:55:50.079317Z","shell.execute_reply.started":"2023-05-19T22:55:50.068616Z","shell.execute_reply":"2023-05-19T22:55:50.078054Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Runtime has 15.6 gigs of memory and 2 processors\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers -q\n!pip install accelerate -q\n!pip install bitsandbytes -q","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:55:51.633641Z","iopub.execute_input":"2023-05-19T22:55:51.633988Z","iopub.status.idle":"2023-05-19T22:56:33.246291Z","shell.execute_reply.started":"2023-05-19T22:55:51.633958Z","shell.execute_reply":"2023-05-19T22:56:33.245072Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.cuda.amp import custom_fwd, custom_bwd\n\nfrom bitsandbytes.functional import quantize_blockwise, dequantize_blockwise","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:56:33.249083Z","iopub.execute_input":"2023-05-19T22:56:33.249490Z","iopub.status.idle":"2023-05-19T22:56:36.411541Z","shell.execute_reply.started":"2023-05-19T22:56:33.249440Z","shell.execute_reply":"2023-05-19T22:56:36.410579Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 117\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/cuda/lib')}\n  warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"#@markdown **create class for bnb** \nimport gc\n\nclass FrozenBNBLinear(nn.Module):\n    def __init__(self, weight, absmax, code, bias=None):\n        assert isinstance(bias, nn.Parameter) or bias is None\n        super().__init__()\n        self.out_features, self.in_features = weight.shape\n        self.register_buffer(\"weight\", weight.requires_grad_(False))\n        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n        self.register_buffer(\"code\", code.requires_grad_(False))\n        self.adapter = None\n        self.bias = bias\n\n    def forward(self, input):\n        output = DequantizeAndLinear.apply(\n            input, self.weight, self.absmax, self.code, self.bias\n        )\n        if self.adapter:\n            output += self.adapter(input)\n        return output\n\n    @classmethod\n    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n        return cls(weights_int8, *state, linear.bias)\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n\n\nclass DequantizeAndLinear(torch.autograd.Function):\n    @staticmethod\n    @custom_fwd\n    def forward(\n        ctx,\n        input: torch.Tensor,\n        weights_quantized: torch.ByteTensor,\n        absmax: torch.FloatTensor,\n        code: torch.FloatTensor,\n        bias: torch.FloatTensor,\n    ):\n        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n        ctx.save_for_backward(input, weights_quantized, absmax, code)\n        ctx._has_bias = bias is not None\n        return F.linear(input, weights_deq, bias)\n\n    @staticmethod\n    @custom_bwd\n    def backward(ctx, grad_output: torch.Tensor):\n        assert (\n            not ctx.needs_input_grad[1]\n            and not ctx.needs_input_grad[2]\n            and not ctx.needs_input_grad[3]\n        )\n        input, weights_quantized, absmax, code = ctx.saved_tensors\n        # grad_output: [*batch, out_features]\n        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n        grad_input = grad_output @ weights_deq\n        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n        return grad_input, None, None, None, grad_bias\n\n\nclass FrozenBNBEmbedding(nn.Module):\n    def __init__(self, weight, absmax, code):\n        super().__init__()\n        self.num_embeddings, self.embedding_dim = weight.shape\n        self.register_buffer(\"weight\", weight.requires_grad_(False))\n        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n        self.register_buffer(\"code\", code.requires_grad_(False))\n        self.adapter = None\n\n    def forward(self, input, **kwargs):\n        with torch.no_grad():\n            # note: both quantuized weights and input indices are *not* differentiable\n            weight_deq = dequantize_blockwise(\n                self.weight, absmax=self.absmax, code=self.code\n            )\n            output = F.embedding(input, weight_deq, **kwargs)\n        if self.adapter:\n            output += self.adapter(input)\n        return output\n\n    @classmethod\n    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n        return cls(weights_int8, *state)\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n\n\ndef quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2**20):\n    assert chunk_size % 4096 == 0\n    code = None\n    chunks = []\n    absmaxes = []\n    flat_tensor = matrix.view(-1)\n    for i in range((matrix.numel() - 1) // chunk_size + 1):\n        input_chunk = flat_tensor[i * chunk_size : (i + 1) * chunk_size].clone()\n        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(\n            input_chunk, code=code\n        )\n        chunks.append(quantized_chunk)\n        absmaxes.append(absmax_chunk)\n    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n    absmax = torch.cat(absmaxes)\n    return matrix_i8, (absmax, code)\n\n\ndef convert_to_int8(model):\n    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n    for module in list(model.modules()):\n        for name, child in module.named_children():\n            gc.collect()\n            if isinstance(child, nn.Linear):\n                print(name, child)\n                setattr(\n                    module,\n                    name,\n                    FrozenBNBLinear(\n                        weight=torch.zeros(\n                            child.out_features, child.in_features, dtype=torch.uint8\n                        ),\n                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n                        code=torch.zeros(256),\n                        bias=child.bias,\n                    ),\n                )\n            elif isinstance(child, nn.Embedding):\n                setattr(\n                    module,\n                    name,\n                    FrozenBNBEmbedding(\n                        weight=torch.zeros(\n                            child.num_embeddings, child.embedding_dim, dtype=torch.uint8\n                        ),\n                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n                        code=torch.zeros(256),\n                    ),\n                )\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:56:36.413581Z","iopub.execute_input":"2023-05-19T22:56:36.414273Z","iopub.status.idle":"2023-05-19T22:56:36.444589Z","shell.execute_reply.started":"2023-05-19T22:56:36.414234Z","shell.execute_reply":"2023-05-19T22:56:36.443522Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import transformers\n#@markdown **create blocking functions** \nclass GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n    def __init__(self, config):\n        super().__init__(config)\n\n        convert_to_int8(self.attn)\n        convert_to_int8(self.mlp)\n\n\nclass GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n    def __init__(self, config):\n        super().__init__(config)\n        convert_to_int8(self)\n        \n\nclass GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n    def __init__(self, config):\n        super().__init__(config)\n        convert_to_int8(self)\n\n\ntransformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:56:36.447053Z","iopub.execute_input":"2023-05-19T22:56:36.447505Z","iopub.status.idle":"2023-05-19T22:56:44.266828Z","shell.execute_reply.started":"2023-05-19T22:56:36.447471Z","shell.execute_reply":"2023-05-19T22:56:44.265640Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(hf_tag,)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:56:44.268490Z","iopub.execute_input":"2023-05-19T22:56:44.268861Z","iopub.status.idle":"2023-05-19T22:56:45.888983Z","shell.execute_reply.started":"2023-05-19T22:56:44.268824Z","shell.execute_reply":"2023-05-19T22:56:45.888056Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/763 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"179c613cb2e24f6b90bf1cd8cf004093"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24a681bdb1e748ca90a27919d53334da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce88bcb57d042888f65652808d03156"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e47b5c4c04594de7b07633a010c2c422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)in/added_tokens.json:   0%|          | 0.00/4.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56d0f3a1a0b94dd28fb8db0d47d78be0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a90665366b6844a29c8157c8231187f5"}},"metadata":{}}]},{"cell_type":"code","source":"model = GPTJForCausalLM.from_pretrained(\n    hf_tag,low_cpu_mem_usage=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:56:45.890425Z","iopub.execute_input":"2023-05-19T22:56:45.890880Z","iopub.status.idle":"2023-05-19T23:01:06.991732Z","shell.execute_reply.started":"2023-05-19T22:56:45.890842Z","shell.execute_reply":"2023-05-19T23:01:06.990821Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"608fa3b9cf2d4f48a52aacdf17c8a2fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/82.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58dccfa2de5644f79b6dc037e4949d86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7852827f74048ee8955a5f9c2738422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00007.bin:   0%|          | 0.00/968M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87dec9402071440c9225ffbb179608c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00007.bin:   0%|          | 0.00/968M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a3e3c12c21b4702b8f8a65264937d6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00003-of-00007.bin:   0%|          | 0.00/984M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbe44d2cc0d547a7819d7026be69a8ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00004-of-00007.bin:   0%|          | 0.00/946M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dce22ce02d848c39fc3233b1919c389"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00005-of-00007.bin:   0%|          | 0.00/968M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b556e6726f564b69816625e0b2ecd279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00006-of-00007.bin:   0%|          | 0.00/984M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b299effcff2f4699842acf988c86c336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00007-of-00007.bin:   0%|          | 0.00/394M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1714dca6574abb86e27ff7af6eb360"}},"metadata":{}},{"name":"stdout","text":"k_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nlm_head Linear(in_features=4096, out_features=50400, bias=True)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28300c21a47f4da9b8eafea5b8e22f91"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at ethzanalytics/gpt-j-6B-8bit-sharded were not used when initializing GPTJForCausalLM: ['transformer.h.4.mlp.fc_out.adapter.0.weight', 'transformer.h.13.attn.k_proj.adapter.2.weight', 'transformer.h.5.mlp.fc_in.adapter.2.weight', 'transformer.h.0.attn.q_proj.adapter.2.weight', 'transformer.h.2.attn.v_proj.adapter.2.weight', 'transformer.h.6.attn.out_proj.adapter.2.weight', 'transformer.h.25.attn.out_proj.adapter.2.weight', 'transformer.h.12.mlp.fc_out.adapter.2.weight', 'transformer.h.13.attn.out_proj.adapter.2.weight', 'transformer.h.25.attn.q_proj.adapter.0.weight', 'transformer.h.26.attn.v_proj.adapter.2.weight', 'transformer.h.27.attn.q_proj.adapter.0.weight', 'transformer.h.18.attn.v_proj.adapter.0.weight', 'transformer.h.23.attn.v_proj.adapter.2.weight', 'transformer.h.16.attn.k_proj.adapter.2.weight', 'transformer.h.10.attn.q_proj.adapter.0.weight', 'transformer.h.3.attn.out_proj.adapter.2.weight', 'transformer.h.3.attn.v_proj.adapter.0.weight', 'transformer.h.17.attn.k_proj.adapter.2.weight', 'transformer.h.12.attn.v_proj.adapter.2.weight', 'transformer.h.7.mlp.fc_out.adapter.2.weight', 'transformer.h.3.attn.v_proj.adapter.2.weight', 'transformer.h.3.mlp.fc_out.adapter.2.weight', 'transformer.h.21.attn.k_proj.adapter.2.weight', 'transformer.h.9.attn.k_proj.adapter.0.weight', 'transformer.h.26.mlp.fc_in.adapter.2.weight', 'transformer.h.9.attn.out_proj.adapter.2.weight', 'transformer.h.21.mlp.fc_out.adapter.2.weight', 'transformer.h.22.attn.k_proj.adapter.0.weight', 'transformer.h.13.attn.q_proj.adapter.2.weight', 'transformer.h.12.attn.k_proj.adapter.0.weight', 'transformer.h.3.mlp.fc_out.adapter.0.weight', 'transformer.h.15.attn.q_proj.adapter.2.weight', 'transformer.h.25.mlp.fc_out.adapter.2.weight', 'transformer.wte.adapter.0.weight', 'transformer.h.1.attn.out_proj.adapter.0.weight', 'transformer.h.4.attn.q_proj.adapter.0.weight', 'transformer.h.14.attn.out_proj.adapter.0.weight', 'transformer.h.17.attn.q_proj.adapter.2.weight', 'transformer.h.25.attn.k_proj.adapter.0.weight', 'transformer.h.13.attn.v_proj.adapter.0.weight', 'transformer.h.4.attn.out_proj.adapter.0.weight', 'transformer.h.27.attn.q_proj.adapter.2.weight', 'transformer.h.5.mlp.fc_out.adapter.2.weight', 'transformer.h.22.attn.k_proj.adapter.2.weight', 'transformer.h.24.attn.out_proj.adapter.0.weight', 'transformer.h.19.attn.k_proj.adapter.0.weight', 'transformer.h.14.mlp.fc_out.adapter.0.weight', 'transformer.h.0.mlp.fc_out.adapter.0.weight', 'transformer.h.20.attn.v_proj.adapter.2.weight', 'transformer.h.26.attn.q_proj.adapter.0.weight', 'transformer.h.27.attn.k_proj.adapter.0.weight', 'transformer.h.25.attn.v_proj.adapter.2.weight', 'transformer.h.24.attn.out_proj.adapter.2.weight', 'transformer.h.0.attn.q_proj.adapter.0.weight', 'transformer.h.11.mlp.fc_out.adapter.0.weight', 'transformer.h.8.attn.k_proj.adapter.2.weight', 'transformer.h.25.attn.out_proj.adapter.0.weight', 'transformer.h.19.mlp.fc_out.adapter.0.weight', 'transformer.h.5.attn.q_proj.adapter.0.weight', 'transformer.h.18.attn.q_proj.adapter.0.weight', 'transformer.h.13.attn.k_proj.adapter.0.weight', 'transformer.h.16.mlp.fc_in.adapter.0.weight', 'transformer.h.23.attn.k_proj.adapter.2.weight', 'transformer.h.9.attn.v_proj.adapter.2.weight', 'transformer.h.8.mlp.fc_in.adapter.0.weight', 'transformer.h.1.attn.v_proj.adapter.2.weight', 'transformer.h.2.attn.v_proj.adapter.0.weight', 'transformer.h.5.attn.k_proj.adapter.2.weight', 'transformer.h.8.attn.out_proj.adapter.2.weight', 'transformer.h.20.attn.q_proj.adapter.2.weight', 'transformer.h.4.attn.v_proj.adapter.2.weight', 'transformer.h.12.mlp.fc_out.adapter.0.weight', 'transformer.h.10.mlp.fc_in.adapter.2.weight', 'transformer.h.17.mlp.fc_in.adapter.0.weight', 'transformer.h.8.attn.q_proj.adapter.2.weight', 'transformer.h.21.attn.v_proj.adapter.2.weight', 'transformer.h.18.attn.q_proj.adapter.2.weight', 'transformer.h.18.attn.k_proj.adapter.0.weight', 'transformer.h.5.attn.v_proj.adapter.2.weight', 'transformer.h.14.mlp.fc_in.adapter.2.weight', 'transformer.h.25.attn.q_proj.adapter.2.weight', 'transformer.h.3.mlp.fc_in.adapter.0.weight', 'transformer.h.15.mlp.fc_in.adapter.2.weight', 'transformer.h.22.mlp.fc_out.adapter.2.weight', 'transformer.h.1.attn.k_proj.adapter.0.weight', 'transformer.h.24.mlp.fc_in.adapter.2.weight', 'transformer.h.26.attn.q_proj.adapter.2.weight', 'transformer.h.0.mlp.fc_in.adapter.0.weight', 'transformer.h.14.attn.q_proj.adapter.2.weight', 'transformer.h.19.attn.v_proj.adapter.2.weight', 'transformer.h.1.mlp.fc_out.adapter.2.weight', 'transformer.h.10.attn.out_proj.adapter.0.weight', 'transformer.h.15.attn.k_proj.adapter.2.weight', 'transformer.wte.adapter.2.weight', 'transformer.h.21.attn.out_proj.adapter.0.weight', 'transformer.h.16.mlp.fc_in.adapter.2.weight', 'transformer.h.21.attn.q_proj.adapter.0.weight', 'transformer.h.20.attn.k_proj.adapter.2.weight', 'transformer.h.11.attn.q_proj.adapter.2.weight', 'transformer.h.15.attn.out_proj.adapter.2.weight', 'transformer.h.10.attn.v_proj.adapter.2.weight', 'transformer.h.27.mlp.fc_in.adapter.2.weight', 'transformer.h.14.attn.v_proj.adapter.2.weight', 'transformer.h.24.mlp.fc_out.adapter.0.weight', 'transformer.h.12.attn.q_proj.adapter.2.weight', 'transformer.h.21.attn.k_proj.adapter.0.weight', 'transformer.h.27.mlp.fc_in.adapter.0.weight', 'transformer.h.18.mlp.fc_in.adapter.0.weight', 'transformer.h.16.mlp.fc_out.adapter.2.weight', 'transformer.h.8.mlp.fc_out.adapter.2.weight', 'transformer.h.2.attn.out_proj.adapter.0.weight', 'transformer.h.14.attn.out_proj.adapter.2.weight', 'transformer.h.19.attn.q_proj.adapter.0.weight', 'transformer.h.5.attn.q_proj.adapter.2.weight', 'transformer.h.26.attn.out_proj.adapter.0.weight', 'transformer.h.18.attn.v_proj.adapter.2.weight', 'transformer.h.10.attn.k_proj.adapter.2.weight', 'transformer.h.7.attn.out_proj.adapter.0.weight', 'transformer.h.10.mlp.fc_out.adapter.0.weight', 'transformer.h.17.mlp.fc_in.adapter.2.weight', 'transformer.h.18.attn.out_proj.adapter.0.weight', 'transformer.h.13.mlp.fc_out.adapter.0.weight', 'transformer.h.1.attn.v_proj.adapter.0.weight', 'transformer.h.17.mlp.fc_out.adapter.0.weight', 'transformer.h.5.attn.k_proj.adapter.0.weight', 'transformer.h.7.mlp.fc_in.adapter.2.weight', 'transformer.h.12.attn.v_proj.adapter.0.weight', 'transformer.h.0.mlp.fc_in.adapter.2.weight', 'transformer.h.9.attn.q_proj.adapter.0.weight', 'transformer.h.16.attn.q_proj.adapter.0.weight', 'transformer.h.11.attn.v_proj.adapter.2.weight', 'transformer.h.10.attn.k_proj.adapter.0.weight', 'transformer.h.12.attn.q_proj.adapter.0.weight', 'transformer.h.27.attn.v_proj.adapter.0.weight', 'transformer.h.3.attn.k_proj.adapter.0.weight', 'transformer.h.4.attn.k_proj.adapter.2.weight', 'transformer.h.7.mlp.fc_in.adapter.0.weight', 'transformer.h.24.attn.q_proj.adapter.0.weight', 'transformer.h.23.attn.v_proj.adapter.0.weight', 'transformer.h.24.attn.k_proj.adapter.2.weight', 'transformer.h.15.attn.out_proj.adapter.0.weight', 'transformer.h.7.attn.k_proj.adapter.2.weight', 'transformer.h.24.attn.v_proj.adapter.0.weight', 'transformer.h.27.attn.out_proj.adapter.2.weight', 'transformer.h.2.mlp.fc_in.adapter.2.weight', 'transformer.h.8.mlp.fc_in.adapter.2.weight', 'transformer.h.4.attn.k_proj.adapter.0.weight', 'transformer.h.26.attn.v_proj.adapter.0.weight', 'transformer.h.25.attn.k_proj.adapter.2.weight', 'transformer.h.24.mlp.fc_in.adapter.0.weight', 'transformer.h.23.attn.out_proj.adapter.0.weight', 'transformer.h.9.mlp.fc_in.adapter.0.weight', 'transformer.h.3.attn.q_proj.adapter.0.weight', 'transformer.h.23.attn.k_proj.adapter.0.weight', 'transformer.h.2.mlp.fc_out.adapter.2.weight', 'transformer.h.11.attn.out_proj.adapter.2.weight', 'transformer.h.6.attn.out_proj.adapter.0.weight', 'transformer.h.22.attn.v_proj.adapter.2.weight', 'transformer.h.23.mlp.fc_out.adapter.0.weight', 'transformer.h.7.attn.v_proj.adapter.2.weight', 'transformer.h.9.attn.q_proj.adapter.2.weight', 'transformer.h.15.attn.q_proj.adapter.0.weight', 'transformer.h.22.mlp.fc_in.adapter.0.weight', 'transformer.h.2.attn.q_proj.adapter.2.weight', 'transformer.h.7.attn.q_proj.adapter.2.weight', 'transformer.h.10.mlp.fc_out.adapter.2.weight', 'transformer.h.13.attn.out_proj.adapter.0.weight', 'transformer.h.22.attn.q_proj.adapter.2.weight', 'transformer.h.13.mlp.fc_in.adapter.0.weight', 'transformer.h.21.attn.v_proj.adapter.0.weight', 'transformer.h.19.mlp.fc_in.adapter.2.weight', 'transformer.h.0.attn.k_proj.adapter.0.weight', 'transformer.h.17.mlp.fc_out.adapter.2.weight', 'transformer.h.19.attn.v_proj.adapter.0.weight', 'transformer.h.25.mlp.fc_in.adapter.2.weight', 'transformer.h.20.attn.k_proj.adapter.0.weight', 'transformer.h.1.mlp.fc_out.adapter.0.weight', 'transformer.h.10.attn.out_proj.adapter.2.weight', 'transformer.h.19.attn.k_proj.adapter.2.weight', 'transformer.h.11.attn.q_proj.adapter.0.weight', 'transformer.h.21.mlp.fc_in.adapter.0.weight', 'transformer.h.6.attn.q_proj.adapter.2.weight', 'transformer.h.9.attn.out_proj.adapter.0.weight', 'transformer.h.5.attn.v_proj.adapter.0.weight', 'transformer.h.23.attn.q_proj.adapter.0.weight', 'transformer.h.26.mlp.fc_out.adapter.2.weight', 'transformer.h.3.mlp.fc_in.adapter.2.weight', 'transformer.h.7.attn.k_proj.adapter.0.weight', 'transformer.h.25.mlp.fc_out.adapter.0.weight', 'transformer.h.20.attn.q_proj.adapter.0.weight', 'transformer.h.11.attn.k_proj.adapter.0.weight', 'transformer.h.11.attn.out_proj.adapter.0.weight', 'transformer.h.26.mlp.fc_out.adapter.0.weight', 'transformer.h.1.attn.k_proj.adapter.2.weight', 'transformer.h.7.attn.out_proj.adapter.2.weight', 'transformer.h.13.attn.q_proj.adapter.0.weight', 'transformer.h.7.attn.v_proj.adapter.0.weight', 'transformer.h.6.mlp.fc_out.adapter.0.weight', 'transformer.h.2.mlp.fc_out.adapter.0.weight', 'transformer.h.4.mlp.fc_in.adapter.0.weight', 'transformer.h.5.attn.out_proj.adapter.0.weight', 'transformer.h.6.attn.k_proj.adapter.2.weight', 'transformer.h.12.mlp.fc_in.adapter.2.weight', 'transformer.h.8.mlp.fc_out.adapter.0.weight', 'transformer.h.0.attn.out_proj.adapter.2.weight', 'transformer.h.23.mlp.fc_in.adapter.2.weight', 'transformer.h.1.attn.q_proj.adapter.0.weight', 'transformer.h.8.attn.v_proj.adapter.0.weight', 'transformer.h.21.attn.out_proj.adapter.2.weight', 'transformer.h.14.attn.q_proj.adapter.0.weight', 'transformer.h.22.attn.out_proj.adapter.0.weight', 'transformer.h.17.attn.q_proj.adapter.0.weight', 'transformer.h.6.mlp.fc_in.adapter.0.weight', 'transformer.h.4.attn.out_proj.adapter.2.weight', 'transformer.h.14.mlp.fc_out.adapter.2.weight', 'transformer.h.11.attn.v_proj.adapter.0.weight', 'transformer.h.20.attn.out_proj.adapter.2.weight', 'transformer.h.12.attn.out_proj.adapter.2.weight', 'transformer.h.17.attn.v_proj.adapter.0.weight', 'transformer.h.2.mlp.fc_in.adapter.0.weight', 'transformer.h.21.attn.q_proj.adapter.2.weight', 'transformer.h.9.attn.v_proj.adapter.0.weight', 'transformer.h.26.attn.k_proj.adapter.0.weight', 'transformer.h.4.mlp.fc_out.adapter.2.weight', 'transformer.h.13.mlp.fc_in.adapter.2.weight', 'transformer.h.6.mlp.fc_out.adapter.2.weight', 'transformer.h.21.mlp.fc_in.adapter.2.weight', 'transformer.h.15.mlp.fc_in.adapter.0.weight', 'transformer.h.15.attn.v_proj.adapter.0.weight', 'transformer.h.1.attn.out_proj.adapter.2.weight', 'transformer.h.7.mlp.fc_out.adapter.0.weight', 'transformer.h.14.attn.k_proj.adapter.0.weight', 'transformer.h.24.mlp.fc_out.adapter.2.weight', 'transformer.h.0.mlp.fc_out.adapter.2.weight', 'transformer.h.2.attn.k_proj.adapter.0.weight', 'transformer.h.23.attn.q_proj.adapter.2.weight', 'transformer.h.26.attn.out_proj.adapter.2.weight', 'transformer.h.22.mlp.fc_in.adapter.2.weight', 'transformer.h.19.mlp.fc_in.adapter.0.weight', 'transformer.h.8.attn.out_proj.adapter.0.weight', 'transformer.h.16.attn.v_proj.adapter.2.weight', 'transformer.h.5.mlp.fc_out.adapter.0.weight', 'transformer.h.6.attn.q_proj.adapter.0.weight', 'transformer.h.18.mlp.fc_out.adapter.0.weight', 'transformer.h.1.mlp.fc_in.adapter.2.weight', 'transformer.h.18.mlp.fc_out.adapter.2.weight', 'transformer.h.18.mlp.fc_in.adapter.2.weight', 'transformer.h.3.attn.q_proj.adapter.2.weight', 'transformer.h.10.attn.q_proj.adapter.2.weight', 'transformer.h.15.attn.v_proj.adapter.2.weight', 'transformer.h.18.attn.out_proj.adapter.2.weight', 'transformer.h.3.attn.out_proj.adapter.0.weight', 'transformer.h.19.mlp.fc_out.adapter.2.weight', 'transformer.h.3.attn.k_proj.adapter.2.weight', 'transformer.h.0.attn.k_proj.adapter.2.weight', 'transformer.h.20.mlp.fc_in.adapter.0.weight', 'transformer.h.23.mlp.fc_in.adapter.0.weight', 'transformer.h.24.attn.q_proj.adapter.2.weight', 'transformer.h.0.attn.out_proj.adapter.0.weight', 'transformer.h.4.attn.q_proj.adapter.2.weight', 'transformer.h.2.attn.k_proj.adapter.2.weight', 'transformer.h.6.attn.v_proj.adapter.2.weight', 'transformer.h.22.attn.out_proj.adapter.2.weight', 'transformer.h.17.attn.k_proj.adapter.0.weight', 'transformer.h.7.attn.q_proj.adapter.0.weight', 'transformer.h.15.mlp.fc_out.adapter.2.weight', 'transformer.h.15.attn.k_proj.adapter.0.weight', 'transformer.h.16.attn.k_proj.adapter.0.weight', 'transformer.h.16.attn.out_proj.adapter.0.weight', 'transformer.h.20.attn.out_proj.adapter.0.weight', 'transformer.h.12.mlp.fc_in.adapter.0.weight', 'transformer.h.4.attn.v_proj.adapter.0.weight', 'transformer.h.19.attn.out_proj.adapter.0.weight', 'transformer.h.11.attn.k_proj.adapter.2.weight', 'transformer.h.23.mlp.fc_out.adapter.2.weight', 'transformer.h.17.attn.out_proj.adapter.2.weight', 'transformer.h.5.mlp.fc_in.adapter.0.weight', 'transformer.h.9.attn.k_proj.adapter.2.weight', 'transformer.h.16.attn.q_proj.adapter.2.weight', 'transformer.h.2.attn.q_proj.adapter.0.weight', 'transformer.h.22.mlp.fc_out.adapter.0.weight', 'transformer.h.27.attn.k_proj.adapter.2.weight', 'transformer.h.4.mlp.fc_in.adapter.2.weight', 'transformer.h.20.mlp.fc_out.adapter.0.weight', 'transformer.h.20.attn.v_proj.adapter.0.weight', 'transformer.h.11.mlp.fc_in.adapter.2.weight', 'transformer.h.15.mlp.fc_out.adapter.0.weight', 'transformer.h.16.attn.out_proj.adapter.2.weight', 'transformer.h.19.attn.out_proj.adapter.2.weight', 'transformer.h.17.attn.out_proj.adapter.0.weight', 'transformer.h.2.attn.out_proj.adapter.2.weight', 'transformer.h.27.attn.v_proj.adapter.2.weight', 'transformer.h.25.attn.v_proj.adapter.0.weight', 'transformer.h.27.mlp.fc_out.adapter.0.weight', 'transformer.h.14.mlp.fc_in.adapter.0.weight', 'transformer.h.9.mlp.fc_out.adapter.2.weight', 'transformer.h.13.attn.v_proj.adapter.2.weight', 'transformer.h.6.mlp.fc_in.adapter.2.weight', 'transformer.h.8.attn.v_proj.adapter.2.weight', 'transformer.h.0.attn.v_proj.adapter.0.weight', 'transformer.h.9.mlp.fc_in.adapter.2.weight', 'transformer.h.0.attn.v_proj.adapter.2.weight', 'transformer.h.20.mlp.fc_out.adapter.2.weight', 'transformer.h.14.attn.k_proj.adapter.2.weight', 'transformer.h.13.mlp.fc_out.adapter.2.weight', 'transformer.h.1.mlp.fc_in.adapter.0.weight', 'transformer.h.24.attn.v_proj.adapter.2.weight', 'transformer.h.20.mlp.fc_in.adapter.2.weight', 'transformer.h.26.mlp.fc_in.adapter.0.weight', 'transformer.h.18.attn.k_proj.adapter.2.weight', 'transformer.h.21.mlp.fc_out.adapter.0.weight', 'transformer.h.22.attn.v_proj.adapter.0.weight', 'transformer.h.10.mlp.fc_in.adapter.0.weight', 'lm_head.adapter.0.weight', 'transformer.h.27.mlp.fc_out.adapter.2.weight', 'transformer.h.1.attn.q_proj.adapter.2.weight', 'transformer.h.16.attn.v_proj.adapter.0.weight', 'transformer.h.19.attn.q_proj.adapter.2.weight', 'transformer.h.23.attn.out_proj.adapter.2.weight', 'transformer.h.27.attn.out_proj.adapter.0.weight', 'transformer.h.5.attn.out_proj.adapter.2.weight', 'transformer.h.9.mlp.fc_out.adapter.0.weight', 'transformer.h.10.attn.v_proj.adapter.0.weight', 'transformer.h.12.attn.k_proj.adapter.2.weight', 'lm_head.adapter.2.weight', 'transformer.h.11.mlp.fc_in.adapter.0.weight', 'transformer.h.17.attn.v_proj.adapter.2.weight', 'transformer.h.6.attn.v_proj.adapter.0.weight', 'transformer.h.22.attn.q_proj.adapter.0.weight', 'transformer.h.8.attn.k_proj.adapter.0.weight', 'transformer.h.11.mlp.fc_out.adapter.2.weight', 'transformer.h.26.attn.k_proj.adapter.2.weight', 'transformer.h.12.attn.out_proj.adapter.0.weight', 'transformer.h.16.mlp.fc_out.adapter.0.weight', 'transformer.h.25.mlp.fc_in.adapter.0.weight', 'transformer.h.6.attn.k_proj.adapter.0.weight', 'transformer.h.24.attn.k_proj.adapter.0.weight', 'transformer.h.14.attn.v_proj.adapter.0.weight', 'transformer.h.8.attn.q_proj.adapter.0.weight']\n- This IS expected if you are initializing GPTJForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing GPTJForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T23:01:28.886772Z","iopub.execute_input":"2023-05-19T23:01:28.887270Z","iopub.status.idle":"2023-05-19T23:01:28.905068Z","shell.execute_reply.started":"2023-05-19T23:01:28.887226Z","shell.execute_reply":"2023-05-19T23:01:28.901069Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\ngenerator = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    device=0 if torch.cuda.is_available() else -1,\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T23:27:10.472926Z","iopub.execute_input":"2023-05-19T23:27:10.473641Z","iopub.status.idle":"2023-05-19T23:27:13.960649Z","shell.execute_reply.started":"2023-05-19T23:27:10.473605Z","shell.execute_reply":"2023-05-19T23:27:13.959367Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import pprint as pp\n\n# @markdown define `generate_text(prompt: str, ...)`\n# @markdown - feel free to adjust textgen params for different results\n\ndef generate_text(\n    prompt: str,\n    temperature=0.7,\n    top_k: int = 50,\n    top_p=0.95,\n    min_length: int = 16,\n    max_length: int = 256,\n    return_full_text=False,\n    **kwargs,\n) -> None:\n\n    print(f\"generating results for input:\\n\\t{prompt}\\n\\t...\")\n    result = generator(\n        prompt,\n        min_length=min_length,\n        max_length=max_length,\n        temperature=temperature,\n        top_k=top_k,\n        top_p=top_p,\n        remove_invalid_values=True,\n        clean_up_tokenization_spaces=True,\n        do_sample=True,\n        return_full_text=return_full_text,\n        pad_token_id=generator.tokenizer.eos_token_id,\n        **kwargs,\n    )\n\n    output = result[0][\"generated_text\"]\n    pp.pprint(output)\n\n    return output\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T00:14:54.759861Z","iopub.execute_input":"2023-05-20T00:14:54.760587Z","iopub.status.idle":"2023-05-20T00:14:54.768930Z","shell.execute_reply.started":"2023-05-20T00:14:54.760543Z","shell.execute_reply":"2023-05-20T00:14:54.767956Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"%%time\nprompt = \"extract entities from this quesion :\\n What Televisions options are available Zaghouan in Gabs Sud with a size of 55 and brand Apple?\\n product category = Televisions \\n region = Zaghouan \\n city =gabs Sud \\n size = 55\\n product name = Apple\\n extract entities from this quesion : Can you recommend a Dell smartphone with a size of 55 located in Tunis in ennasr? \" #@param {type:\"string\"}\nresult = generate_text(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T23:48:44.883320Z","iopub.execute_input":"2023-05-19T23:48:44.883727Z","iopub.status.idle":"2023-05-19T23:48:57.507886Z","shell.execute_reply.started":"2023-05-19T23:48:44.883693Z","shell.execute_reply":"2023-05-19T23:48:57.506960Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"generating results for input:\n\textract entities from this quesion :\n What Televisions options are available Zaghouan in Gabs Sud with a size of 55 and brand Apple?\n product category = Televisions \n region = Zaghouan \n city =gabs Sud \n size = 55\n product name = Apple\n extract entities from this quesion : Can you recommend a Dell smartphone with a size of 55 located in Tunis in ennasr? \n\t...\n('\\n'\n ' product category = Smartphones\\n'\n ' region = Tunis \\n'\n ' city = ennasr\\n'\n ' size = 55\\n'\n ' product name = Dell\\n'\n '\\n'\n 'How to extract entities from')\nCPU times: user 12.6 s, sys: 10.6 ms, total: 12.6 s\nWall time: 12.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nprompt = \"extract query entities from this question like the product name , size , city , region and the product name :\\n What Televisions options are available Zaghouan in Gabs Sud with a size of 55 and brand Apple?\"\nresult = generate_text(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T23:38:22.378101Z","iopub.execute_input":"2023-05-19T23:38:22.379128Z","iopub.status.idle":"2023-05-19T23:38:52.622298Z","shell.execute_reply.started":"2023-05-19T23:38:22.379078Z","shell.execute_reply":"2023-05-19T23:38:52.621162Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"generating results for input:\n\textract query entities from this question like the product name , size , city , region and the product name :\n What Televisions options are available Zaghouan in Gabs Sud with a size of 55 and brand Apple?\n\t...\n('\\n'\n '\\n'\n \"I'm trying to make a query which can extract the product name, size, city, \"\n 'region and the product name :\\n'\n 'What Televisions options are available Zaghouan in Gabs Sud with a size of '\n '55 and brand Apple?\\n'\n '\\n'\n 'A:\\n'\n '\\n'\n 'Try this:\\n'\n 'SELECT `product_name`, `size`, `city`, `region`, `product_name`')\nCPU times: user 30.2 s, sys: 17.6 ms, total: 30.2 s\nWall time: 30.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nprompt = \"Please extract the following entities from the given question: product name, size, city, and region , put them into a list .\\nQuestion: What are the available options for Televisions in Zaghouan, Gabs Sud, with a size of 55 and brand Apple?\"\nresult = generate_text(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T00:36:26.463734Z","iopub.execute_input":"2023-05-20T00:36:26.464157Z","iopub.status.idle":"2023-05-20T00:36:57.851501Z","shell.execute_reply.started":"2023-05-20T00:36:26.464125Z","shell.execute_reply":"2023-05-20T00:36:57.850449Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"generating results for input:\n\tPlease extract the following entities from the given question: product name, size, city, and region , put them into a list .\nQuestion: What are the available options for Televisions in Zaghouan, Gabs Sud, with a size of 55 and brand Apple?\n\t...\n('\\n'\n '\\n'\n 'A:\\n'\n '\\n'\n 'Product Name:\\n'\n 'Televisions\\n'\n 'Size:\\n'\n '55\\n'\n 'Brand:\\n'\n 'Apple\\n'\n 'City:\\n'\n 'Zaghouan, Gabs Sud\\n'\n 'Region:\\n'\n '\\n'\n 'If the question is asking for the available options with the brand apple for '\n 'size 55 then the options are:\\n'\n 'Televisions:\\n'\n '1) Samsung\\n'\n '2) LG\\n'\n '3) Sony\\n'\n '4) Panasonic\\n'\n '\\n')\nCPU times: user 31.3 s, sys: 24.7 ms, total: 31.3 s\nWall time: 31.4 s\n","output_type":"stream"}]}]}